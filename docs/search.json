[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thesis-Analysen in R",
    "section": "",
    "text": "Vorwort\nDieses mit quarto erstellte Dokument wurde als Crashkurs zur Nutzung von R zur Auswertung in Abschlussarbeiten im Rahmen des Betreuungskolloquiums der Abteilung für Psychologische Methodenlehre der CAU zu Kiel erstellt.\n\nAbschnitt 1: Import und Aufbereitung von Psychopy-Daten\nDieser Abschnitt beschäftigt sich ausschließlich mit dem Stapel-Import eines Haufens an Dateien einzelner Proband:innen. Die Beispiele beziehen sich auch Psychopy/Pavlovia-typische Datensammlungen, können aber auch auf andere Beispiele angewandt werden.\nDas Lesen des Abschnittes sollte Leser:innen dazu befähigen, purrr- und readr-Funktionalitäten zu nutzen, um alle in einem Ordner vorliegenden Dateien zu importieren. Außerdem können Leser:innen Funktionen aus dem tidyr-Paket nutzen, um Daten in das long-Format zu überführen.\n\n\nAbschnitt 2: Grafiken mit ggplot2\nIn diesem Abschnitt wird ein kurzer Abriss zur Auffrischung der Logik hinter der grammar of graphics präsentiert. Anschließend werden Beispiele für die Erstellung einiger der häufigsten Grafik-Typen gezeigt. Abschließend wird ein Überblick für potentiell interessante andere Stellen zur Referenz eingeführt.\nNach diesem Abschnitt sollten Leser die grundlegenden Prinzipien zur Erstellung von Grafiken mit ggplot2 kennen und auf häufig genutzte Grafikformate anwenden können. Außerdem sollte ein Überblick an möglichen anderen Stellen zur weiteren Information gewonnen sein.\n\n\nAbschnitt 3: Erstellung von APA-konformen Tabellen\nDieser Abschnitt beschäftigt sich mit der Erstellung APA-konformer Tabellen in R. Dazu wird zum Einen auf den spezifischen Export mit apaTables, zum Anderen auf den flexibleren Ansatz mit flextable eingegangen.\nNach diesem Abschnitt sollten Leser in der Lage sein, Tabellen gängiger Analysen aus R im APA-Format zu exportieren. Außerdem soll die Fähigkeit vermittelt werden, die Erstellung von APA-konformen Tabellen mit flextable durchzuführen.\n\n\nAbschnitt 4: Methodenteil in quarto\nDieser Abschnitt beschäftigt sich mit der Erstellung von Textabschnitten oder ganzer Arbeiten mit quarto, dem Texterstellungs-Framework, das von Posit zur direkten Erstellung von Texten in RStudio unterstützt wird.\nAm Ende dieses Abschnittes sollten Leser in der Lage sein quarto-Dokumente zu erstellen, ihre Auswertung in Code-chunks durchführen können und die Ergebnisse in pdf und word exportieren können."
  },
  {
    "objectID": "_quarto/intro.html",
    "href": "_quarto/intro.html",
    "title": "1  Warum dieses Skript?",
    "section": "",
    "text": "Weil händisches kopieren doof ist.\nWeil dieselbe Formatierung 20x anzuwenden doof ist.\nWeil Psychologie-Studis der CAU natürlich ihre Auswertung eh schon in R machen1.\n\n\n\n\n\n\nweil SPSS doof ist.↩︎"
  },
  {
    "objectID": "_quarto/wrangling.html#batch-import",
    "href": "_quarto/wrangling.html#batch-import",
    "title": "2  Import und Aufbereitung von Psychopy-Daten",
    "section": "2.1 Batch-Import",
    "text": "2.1 Batch-Import\nPsychopy und Pavlovia schreiben Ihre Daten im long-Format raus, die dem kommenden Beispiel ähneln:\n\nread_csv('../data/1_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv') %>% \n  head()\n\nNew names:\nRows: 47 Columns: 20\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(9): Bild, weiter_Willkommen.keys, Ergebnisse, Sicherheit, key_resp.key... dbl\n(10): Ergebnisse_Loop.thisRepN, Ergebnisse_Loop.thisTrialN, Ergebnisse_L... lgl\n(1): ...20\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...20`\n\n\n# A tibble: 6 × 20\n  Bild   Ergeb…¹ Ergeb…² Ergeb…³ Ergeb…⁴ weite…⁵ weite…⁶ Entsc…⁷ Ergeb…⁸ Siche…⁹\n  <chr>    <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>   <dbl> <chr>     <dbl>\n1 <NA>        NA      NA      NA      NA space      5.49      NA <NA>         NA\n2 Tabel…       0       0       0      44 <NA>      NA          1 andere…       1\n3 Tabel…       0       1       1      10 <NA>      NA          1 andere…       3\n4 Tabel…       0       2       2      32 <NA>      NA          1 andere…       4\n5 Tabel…       0       3       3      40 <NA>      NA          1 andere…       1\n6 Tabel…       0       4       4      16 <NA>      NA          1 andere…       3\n# … with 10 more variables: Sicherheit <chr>, key_resp.keys <chr>,\n#   key_resp.rt <dbl>, participant <dbl>, session <chr>, date <chr>,\n#   expName <chr>, psychopyVersion <chr>, frameRate <dbl>, ...20 <lgl>, and\n#   abbreviated variable names ¹​Ergebnisse_Loop.thisRepN,\n#   ²​Ergebnisse_Loop.thisTrialN, ³​Ergebnisse_Loop.thisN,\n#   ⁴​Ergebnisse_Loop.thisIndex, ⁵​weiter_Willkommen.keys, ⁶​weiter_Willkommen.rt,\n#   ⁷​Entscheidung.response, ⁸​Ergebnisse, ⁹​Sicherheit_Entscheidung.response\n\n\nDie Daten oben kommen aus einer FOV-Studie aus dem WS21 in der untersucht wurde, wie sicher sich Proband:innen bei der Entscheidung für einen t-Test oder einen anderen Test basierend auf Levene- und KS-Test-p-Werten sind und wie sehr sie sich in ihrer Entscheidung sicher sind..\nFür jeden Probanden wird dabei eine Datei erstellt, so dass der data-folder gerne mal wie in Abb. Figure 2.1 aussehen kann.\n\n\n\nFigure 2.1: Ansicht des Daten-Ordners\n\n\nUm Auswertungen vorzubereiten müssen diese einzelnen Dateien erstmal zusammengefügt werden.\nDazu brauchen wir erstmal einen Vektor mit allen csv-files im Ordner:\n\n # bei mir liegt der data-Ordner im Verzeichnis über dem in dem sich das Skript befindet\nlist.files(path = '../data/',\n           pattern = 'csv') %>% \n  str()\n\n chr [1:51] \"1_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv\" ...\n\n\nDa bei mir ein relativer Pfad nötig ist würden die files so nicht gefunden werden, deswegen müssen wir noch das full.names-Argument auf TRUE setzen.\n\nlist.files(path = '../data/',\n           pattern = 'csv',\n           full.names = T) %>% \n  str()\n\n chr [1:51] \"../data//1_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv\" ...\n\n\nDie so erstellten Pfade können wir dann im batch öffnen und einlesen. Dazu kann der wrapper map_dfr um map und bind_rows aus dem purrr-Paket helfen:\n\nall_vpn <- list.files(path = '../data/',\n           pattern = 'csv',\n           full.names = T) %>% \n  map_dfr(~read_csv(.))\n\nError in `dplyr::bind_rows()`:\n! Can't combine `..26$Ergebnisse_Loop.thisRepN` <double> and `..27$Ergebnisse_Loop.thisRepN` <character>.\n\n\nDer Fehler kommt daher, dass einzelne Dokumente zu kurz sind und die Spaltentypen deswegen nicht erkannt werden. Hier gibt es drei Möglichkeiten mit dem Problem umzugehen:\n\nDer automatische WegDer manuelle WegDer hässliche Weg\n\n\nBei Psychopy kann der Fehler oben nur auftreten wenn\n\netwas am Skript geändert wurde wodurch ein Datentyp in einer Datei nicht mehr stimmt.\nein:e Proband:in vor dem ersten Trial eines Blocks abgebrochen hat.\n\nIm ersten Fall habt Ihr ganz andere Probleme und solltet im Detail darüber nachdenken wie ihr das löst - oder den manuellen Weg wählen. Im zweiten Fall könnt Ihr alle zu kleinen files einfach filtern:\n\nfiles <- tibble(\n  path = list.files(\n    path = '../data/',\n    pattern = 'csv',\n    full.names = T\n  ),\n  size = file.size(path)\n)\n\nfiles %>% \n  head()\n\n# A tibble: 6 × 2\n  path                                                         size\n  <chr>                                                       <dbl>\n1 ../data//1_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv   6597\n2 ../data//10_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv  6617\n3 ../data//11_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv  6609\n4 ../data//12_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv  6598\n5 ../data//13_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv  6599\n6 ../data//14_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv  6594\n\nall_vpn <- files %>% \n  filter(size > mean(size)) %>% \n  pull(path) %>% \n  map_dfr(~read_csv(.))\n\n\n\nDie zweite Möglichkeit ist es, in read_csv die erwarteten Spalten-Typen anzugeben.\nIn meinem Fall sieht das so aus:\n\nall_vpn <- list.files(path = '../data/',\n           pattern = 'csv',\n           full.names = T) %>% \n  map_dfr(~read_csv(.,col_types = 'cnnnncnncnccnnccccnl'))\n\n\n\nDer uneleganteste Weg ist es erstmal alle Spalten als character zu importieren und dann die nötigen Spalten umzuwandeln:\n\nall_vpn <- list.files(path = '../data/',\n           pattern = 'csv',\n           full.names = T) %>% \n  map_dfr(~read_csv(.,col_types = cols(.default = 'c')))\n\nall_vpn %>% \n  glimpse()\n\nRows: 20,629\nColumns: 23\n$ Bild                             <chr> NA, \"Tabellen/45.png\", \"Tabellen/11.p…\n$ Ergebnisse_Loop.thisRepN         <chr> NA, \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\"…\n$ Ergebnisse_Loop.thisTrialN       <chr> NA, \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"…\n$ Ergebnisse_Loop.thisN            <chr> NA, \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"…\n$ Ergebnisse_Loop.thisIndex        <chr> NA, \"44\", \"10\", \"32\", \"40\", \"16\", \"27…\n$ weiter_Willkommen.keys           <chr> \"space\", NA, NA, NA, NA, NA, NA, NA, …\n$ weiter_Willkommen.rt             <chr> \"5.486211061477661\", NA, NA, NA, NA, …\n$ Entscheidung.response            <chr> NA, \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"…\n$ Ergebnisse                       <chr> NA, \"anderer Test\", \"anderer Test\", \"…\n$ Sicherheit_Entscheidung.response <chr> NA, \"1\", \"3\", \"4\", \"1\", \"3\", \"3\", \"1\"…\n$ Sicherheit                       <chr> NA, \"sehr sicher\", \"unsicher\", \"gar n…\n$ key_resp.keys                    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ key_resp.rt                      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ participant                      <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ session                          <chr> \"001\", \"001\", \"001\", \"001\", \"001\", \"0…\n$ date                             <chr> \"2022_Feb_14_1853\", \"2022_Feb_14_1853…\n$ expName                          <chr> \"Experiment_Vorüberlegungen\", \"Experi…\n$ psychopyVersion                  <chr> \"2021.2.3\", \"2021.2.3\", \"2021.2.3\", \"…\n$ frameRate                        <chr> \"59.783176973314745\", \"59.78317697331…\n$ ...20                            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ RT                               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Accuracy                         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ group                            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nAus diesem Datensatz brauchen wählen wir dann die Spalten aus, die wir brauchen und wandeln die Reaktionszeiten um (und filtern leere Zeilen).\n\ndf <- all_vpn %>% \n  select(participant, Entscheidung.response, Ergebnisse, Sicherheit_Entscheidung.response, Sicherheit)\nglimpse(df)\n\nRows: 20,629\nColumns: 5\n$ participant                      <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n$ Entscheidung.response            <chr> NA, \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"…\n$ Ergebnisse                       <chr> NA, \"anderer Test\", \"anderer Test\", \"…\n$ Sicherheit_Entscheidung.response <chr> NA, \"1\", \"3\", \"4\", \"1\", \"3\", \"3\", \"1\"…\n$ Sicherheit                       <chr> NA, \"sehr sicher\", \"unsicher\", \"gar n…\n\ndf <- df %>% \n  mutate(across(matches('response'), ~as.numeric(.)),\n         participant = as.numeric(participant))\n\ndf <- df %>% \n  filter(!is.na(Ergebnisse))\n\ndf %>% \n  glimpse()\n\nRows: 2,205\nColumns: 5\n$ participant                      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Entscheidung.response            <dbl> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2…\n$ Ergebnisse                       <chr> \"anderer Test\", \"anderer Test\", \"ande…\n$ Sicherheit_Entscheidung.response <dbl> 1, 3, 4, 1, 3, 3, 1, 3, 1, 2, 2, 3, 1…\n$ Sicherheit                       <chr> \"sehr sicher\", \"unsicher\", \"gar nicht…\n\n\n\n\n\nMit dem so umgewandelten Datensatz können wir dann wie gewohnt weiterarbeiten.\nZum Beispiel können wir uns die durchschnittliche Sicherheit pro Proband:in und Entscheidung ausgeben lassen:\n\nresponse_summary <- df %>% \n  group_by(participant, Ergebnisse) %>% \n  summarise(Sicherheit = mean(Sicherheit_Entscheidung.response))\n\n`summarise()` has grouped output by 'participant'. You can override using the\n`.groups` argument.\n\nresponse_summary %>% \n  head()\n\n# A tibble: 6 × 3\n# Groups:   participant [3]\n  participant Ergebnisse   Sicherheit\n        <dbl> <chr>             <dbl>\n1           1 anderer Test       2.65\n2           1 t-Test             2.57\n3           2 anderer Test       2.33\n4           2 t-Test             2.52\n5           3 anderer Test       2.18\n6           3 t-Test             2.54"
  },
  {
    "objectID": "_quarto/wrangling.html#zusammenfügen",
    "href": "_quarto/wrangling.html#zusammenfügen",
    "title": "2  Import und Aufbereitung von Psychopy-Daten",
    "section": "2.2 Zusammenfügen",
    "text": "2.2 Zusammenfügen\nIn den meisten Fällen werdet Ihr neben Psychopy-Daten noch wo anders Fragebogen dargeboten haben, die Ihr mit den Daten zusammenfügen müsst.\nIn unserem Beispiel existiert eine .xlsx-Datei, die die Limesurvey-Ergebnisse beinhaltet.\nUm die zusammengefassten Ergebnisse an diese anzufügen müssen wir sie zuerst importieren:\n\nlimesurvey_results <- openxlsx::read.xlsx('../data/LimeSurvey Daten.xlsx')\n\nlimesurvey_results %>% \n  glimpse()\n\nRows: 50\nColumns: 4\n$ Bitte.geben.Sie.Ihr.Geschlecht.an. <chr> \"weiblich\", \"weiblich\", \"männlich\",…\n$ Bitte.geben.Sie.Ihr.Alter.an.      <dbl> 26, 18, 21, 21, 32, 32, 29, 29, 24,…\n$ `Was.machen.Sie.beruflich?`        <chr> \"Studium\", \"Studium\", \"Psychotherap…\n$ `VP-Nr`                            <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, …\n\n\nDie Zusammenfassungen sind noch im long-Format, können also nicht so einfach mit den LS-Daten im wide-Format zusammengeführt werden. Also erst einmal pivotieren:\n\nresponse_summary <- response_summary %>% \n  pivot_wider(names_from = 'Ergebnisse',\n              values_from = 'Sicherheit')\n\nresponse_summary %>% \n  head()\n\n# A tibble: 6 × 3\n# Groups:   participant [6]\n  participant `anderer Test` `t-Test`\n        <dbl>          <dbl>    <dbl>\n1           1           2.65     2.57\n2           2           2.33     2.52\n3           3           2.18     2.54\n4           4           2.29     2.57\n5           5           2.24     2.54\n6           6           1.94     2.48\n\n\nDie beiden Ergebnisse können wir jetzt kombinieren:\n\nvp_level_data <- response_summary %>% \n  left_join(limesurvey_results,\n            by = c('participant' = 'VP-Nr'))\n\nvp_level_data %>% \n  glimpse()\n\nRows: 49\nColumns: 6\nGroups: participant [49]\n$ participant                        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, …\n$ `anderer Test`                     <dbl> 2.647059, 2.333333, 2.176471, 2.294…\n$ `t-Test`                           <dbl> 2.571429, 2.518519, 2.535714, 2.571…\n$ Bitte.geben.Sie.Ihr.Geschlecht.an. <chr> \"weiblich\", \"weiblich\", \"männlich\",…\n$ Bitte.geben.Sie.Ihr.Alter.an.      <dbl> 26, 18, 21, 21, 32, 32, 29, 29, 24,…\n$ `Was.machen.Sie.beruflich?`        <chr> \"Studium\", \"Studium\", \"Psychotherap…\n\n\nAuf den Daten können wir dann arbeiten:\n\nvp_level_data %>% \n  select(where(is.numeric)) %>% \n  cor()\n\n                              participant anderer Test      t-Test\nparticipant                    1.00000000  -0.29763927 -0.01798315\nanderer Test                  -0.29763927   1.00000000 -0.35251805\nt-Test                        -0.01798315  -0.35251805  1.00000000\nBitte.geben.Sie.Ihr.Alter.an. -0.09077279  -0.07051619  0.08474383\n                              Bitte.geben.Sie.Ihr.Alter.an.\nparticipant                                     -0.09077279\nanderer Test                                    -0.07051619\nt-Test                                           0.08474383\nBitte.geben.Sie.Ihr.Alter.an.                    1.00000000"
  },
  {
    "objectID": "_quarto/graphics.html#grammar-of-graphics",
    "href": "_quarto/graphics.html#grammar-of-graphics",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.1 Grammar of graphics",
    "text": "3.1 Grammar of graphics\nHadley Wickhams Paket ggplot2 versucht, die Erstellung von Grafiken in einer einheitlichen Grammatik, der “grammar of graphics”, auszudrücken. Das Ziel hier ist es, nicht mehr in “Scatterplot” und “Boxplot” als einzelne Kategorien zu denken und diese einzeln erstellen lernen zu müssen, sondern alle Abbildungen mit derselben Logik erstellen zu können.\nIn Seinem Paper (Wickham, 2010) werden die folgenden Komponenten als grundlegende Bausteine einer Grafik eingeführt:\n\n\na default dataset and set of mappings from variables to aesthetics,\none or more layers, with each layer having one geometric object, one statistical trans- formation, one position adjustment, and optionally, one dataset and set of aesthetic mappings,\none scale for each aesthetic mapping used,\na coordinate system,\nthe facet specification. (Wickham, 2010, p. 8)\n\n\n\n3.1.1 Komponenten eines Plots\nWir müssen für einen Plot also überlegen:\n\nwelche Daten wir auf welche Aesthetics mappen\nwelche geometrischen Objekte wir in welcher Reihenfolge auf die Grafik layer wollen und ob diese optionale andere Daten benötigen\nwelche Skala wir für die Mappings nutzen wollen\nwelches Koordinatensystem wir nutzen wollen\nin welchen Facetten wir die Daten darstellen wollen"
  },
  {
    "objectID": "_quarto/graphics.html#komponenten-in-ggplot2",
    "href": "_quarto/graphics.html#komponenten-in-ggplot2",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.2 Komponenten in ggplot2",
    "text": "3.2 Komponenten in ggplot2\n\n3.2.0.1 Beispieldaten\n\n\n\n\n\nPinguine im Eis\n\n\n\nIm palmerpenguins-Paket werden Pinguin-Beobachtungen der Palmer-Station in der Antarktis zur Verfügung gestellt:\n\npalmerpenguins::penguins %>% \n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  <fct>   <fct>              <dbl>         <dbl>       <int>   <int> <fct> <int>\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA <NA>   2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n6 Adelie  Torgersen           39.3          20.6         190    3650 male   2007\n# … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g\n\n\n\n\n\n1. Daten und Aesthetics - ggplot() + aes()2. Geometrische Objekte - geom_*3. Skalen - scale_*4. Koordinatensystem coord_*5. Facetten - facet_*\n\n\nWir wollen den Zusammenhang zwischen Körpergewicht und Schnabellänge über die Spezien betrachten. Dafür legen wir die “Leinwand” des Plots mit den zentralen mappings an:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species))\n\n\n\n\n\n\nDiesem Plot fügen wir Punkte als geometrische Objekte hinzu, die uns zu einem Scatterplot führen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWir als weiteres geometrisches Objekt könnten wir uns zum Beispiel wünschen, die Mittelwerte pro Gruppe mit den Abweichungen auf x- und y-Achse darzustellen. Dazu müssen wir zuerst diesen neuen Datensatz berechnen:\n\npenguin_means <- palmerpenguins::penguins %>% \n  group_by(species) %>% \n  summarise(across(c(bill_length_mm, body_mass_g), ~mean(., na.rm=T)))\n\n…und auf den Plot in einem neuen Layer hinzufügen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFür den Layer können wir auch speifische geometrische Eigenschaften einfügen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point() +\n  geom_point(data=penguin_means, shape = 3)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nOder direkt ein neues Mapping einführen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original')) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nUnd auch beide Varianten kombinieren:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nDie Symbole und Farben haben genau wie x- und y- Koordinaten als ästhetische Mappings eigene Skalen. Wenn uns also die Farben nicht passen, können wir einfach eine andere Skala setzen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nGenauso können wir einfach die Skala der Symbole an unsere Wünsche anpassen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nDas Koordinatensystem passt von der Auflösung erstmal, aber wir wollen eine direkte Zuordnung von 10 mm Schnabellänge zu 1000 g Körpermasse. Dazu fügen wir eine coord_*-Spezifikation an:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))+\n  coord_fixed(ratio = 10/1000)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nAls letzte Komponente überlegen wir uns, dass die verschiedenen Beobachtungspunkte als Einteilung interessant sein könnten und wir diese getrennt betrachten wollen. Um diese Facettierung umzusetzen ergänzen wir zuerst den Mittelwerts-Datensatz um den Beobachtungsort:\n\npenguin_means <- palmerpenguins::penguins %>% \n  group_by(species, island) %>% \n  summarise(across(c(bill_length_mm, body_mass_g), ~mean(., na.rm=T)))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\nUm dem Graphen anschließend die Facettierung anzufügen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "_quarto/graphics.html#apa-styling",
    "href": "_quarto/graphics.html#apa-styling",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.3 APA-Styling",
    "text": "3.3 APA-Styling\nAus Julias Folien1 kommt folgende Checkliste für APA-Grafiken:\n\n\n\nScreenshot der APA-Checkliste\n\n\nWir müssen also noch\n\ndie Elemente klar labeln\nsicherstellen dass der Font passt\ndie Legende unter dem Bild anordnen\ndie Beschriftung der Legende überprüfen\n\nDaneben habe ich noch ein persönliches Problem mit dem grauen Hintergrund, damit fangen wir an:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  theme_light()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIn diesem Zusammenhang können wir auch gleich Base-Font und Schriftgröße setzen. theme_light setzt die kleinste Schriftgröße auf .8 * die base_size, wenn wir minimal 8pt große Schrift haben wollen.\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  theme_light(base_family = 'Helvetical',\n              base_size = 10)\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nAls nächstes die Anpassung der Achsen- und Legenden-Labels:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'mean'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(original = 20, mean = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  theme_light(base_family = 'Helvetical',\n              base_size = 10) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDie Namen der Formen sind noch nicht title-cased, das können wir am einfachsten in der Definition ändern:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  theme_light(base_family = 'Helvetical',\n              base_size = 10) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nDie Legende muss dann noch an die Unterseite des Graphen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  theme_light(base_family = 'Helvetical',\n              base_size = 10) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau') +\n  theme(legend.position = 'bottom')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n:::\nUnd damit ist die Formatierung fertig."
  },
  {
    "objectID": "_quarto/graphics.html#convenient-standards",
    "href": "_quarto/graphics.html#convenient-standards",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.4 Convenient Standards",
    "text": "3.4 Convenient Standards\nDie beiden theme-Funktionen müssten wir so an jede Grafik anfügen. Solche Wiederholungen sind schlechter Stil und stören beim Lesen des Skripts, deswegen bietet ggplot2 convenience-Funktionen um allgemeine Einstellungen zu setzen. Mit dem folgenden Snippet am Anfang des Skripts werden die Standards für alle Grafiken genutzt:\n\nmy_theme <-  theme_light(base_family = 'Helvetical',\n              base_size = 10) +\n  theme(legend.position = 'bottom')\n\ntheme_set(my_theme)\n\nSo kann ich jetzt einfach Beispielsweise ein eingefärbtes Histogramm für die Flossen-Länge mit den gesetzten Standards erstellen:\n\npalmerpenguins::penguins %>% \n  ggplot(aes(x = flipper_length_mm,\n             fill = sex)) +\n  geom_histogram(binwidth = 5)\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "_quarto/graphics.html#export",
    "href": "_quarto/graphics.html#export",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.5 Export",
    "text": "3.5 Export\nZum Abschluss können wir die Grafiken exportieren.\nDie Textgröße ist in pt gesetzt, deswegen sollten wir nach dem Export die Größe im besten Fall nicht mehr viel ändern.\nEine Din A4-Seite ist 8.2 x 11.6 Zoll groß. Wenn wir eine Grafik auf 80% der Seitenbreite haben wollen, brauchen wir also eine 6.56 Zoll breite Grafik.\nZum Speichern setzen wir unsere Grafik und die Maße in ggsave ein:\n\np <- palmerpenguins::penguins %>% \n  ggplot(aes(x = bill_length_mm, \n             y = body_mass_g,\n             color = species)) + \n  geom_point(aes(shape = 'Original'),\n             alpha = .5) +\n  geom_point(data=penguin_means,\n             aes(shape = 'Mittelwert'),\n             size = 3) +\n  scale_color_viridis_d(end = 0.7) +\n  scale_shape_manual(values = c(Original = 20, Mittelwert = 3))+\n  coord_fixed(ratio = 10/1000) +\n  facet_wrap(~island) +\n  labs(x = 'Schnabellänge (mm)',\n       y = 'Körpergewicht (g)',\n       color = 'Pinguin-Spezies',\n       shape = 'Aggregations-Niveau')\n\nggsave(plot = p,\n       filename = '../imgs/penguin_scatter.png',\n       width = 6.56,units = 'in')\n\nSaving 6.56 x 5 in image\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\nDer Export sieht so aus:\n Erstens können wir schonmal feststellen dass die Grafik ruhig schmaler werden kann. Die Export-Funktion hat uns eine Höhe von 6.74 Inches mitgeteilt, das können wir ruhig auf 4 inches reduzieren.\nZweitens ist die Legende ein bisschen kaputt gegangen.\nDazu gibt es vier Möglichkeiten zur Anpassung:\n\nLegende mit ZeilenumbrüchenLegende mit kleinerem TextLegende im Graphen\n\n\n\np_linebreaks <- p +\n  guides(color = guide_legend(nrow = 3),\n         shape = guide_legend(nrow = 2))\n\nggsave(plot = p_linebreaks,\n       filename = '../imgs/penguin_scatter_linebreaks.png',\n       width = 6.56, height = 4, units = 'in')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nGrafik mit Legende mit Linebreaks\n\n\n\n\n\np_smaller_text <- p +\n  theme(legend.title = element_text(size = 10,\n                                    colour = 'darkgrey'))\n\nggsave(plot = p_smaller_text,\n       filename = '../imgs/penguin_scatter_smaller_text.png',\n       width = 6.56, height = 4,units = 'in')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nGrafik mit kleineren Legenden-Überschriften\n\n\n\n\n\np_legend_in_plot <- p + \n  theme(\n    # Legende an oberer rechter Ecke orientieren\n    legend.justification=c(1,1),\n    # Legende an obere rechte Ecke schieben\n    legend.position=c(1,0.98), \n    # Legenden-Hintergrund fast transparent machen\n    legend.background = element_rect(fill = rgb(1,1,1,.5)),\n    # Hintergrund der Legenden-Felder fast transparent machen\n    legend.key = element_rect(fill = rgb(1,1,1,.5)))\n\nggsave(plot = p_legend_in_plot,\n       filename = '../imgs/penguin_scatter_legend_in_plot.png',\n       width = 6.56, height = 4,units = 'in')\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nGrafik mit Legende in plot-Region"
  },
  {
    "objectID": "_quarto/graphics.html#hilfreiche-links",
    "href": "_quarto/graphics.html#hilfreiche-links",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.6 Hilfreiche Links",
    "text": "3.6 Hilfreiche Links\n\nfür einen Überblick über alle möglichen Kompenenten empfiehlt sich das von posit herausgegebene cheatsheet\ndas Kapitel zu Datenvisualisierungen in Grolemund & Wickham (2016) ist sehr gut und geht weiter ins Detail als hier möglich ist\nIm Paket ggpubr wird ggplot2 genutzt um eine Reihe von “publication ready plots” zu erstelllen\nUnter diesem Link ist eine shiny-App zur interaktiven Erstellung von ggplot-Graphen zu finden\nUnter diesem Link findet sich eine Sammlung von Farben, Formen, usw., die mit ggplot nutzbar sind."
  },
  {
    "objectID": "_quarto/graphics.html#aufgabe",
    "href": "_quarto/graphics.html#aufgabe",
    "title": "3  Die Grammar of graphics und ggplot2",
    "section": "3.7 Aufgabe",
    "text": "3.7 Aufgabe\n\nLese den im Repo zu diesem Skript zur Verfügung gestellten Datensatz example.csv ein. Dazu kann einfach der folgende Chunk genutzt werden:\n\n\nread_csv('https://raw.githubusercontent.com/MBrede/r_thesis_tools/main/data/example.csv')\n\n\nStelle die Reaktionszeiten und Accuracies in einem Scatterplot dar.\nFärbe den Graphen nach Gruppen ein\nFüge Mittelwerte und Standardabweichungen pro Gruppe hinzu. Füge die Standardabweichungen dabei mit geom_linerange in zwei layern hinzu (einem für die x- und einem für die y-Richtung)\nPasse die Grafik so an, dass sie APA-konform ist\nMache die Grafik so unästhetisch, wie es die APA-Richtlinien zulassen. Hier sind Fonts, Farben und Formen zu finden.\n\n\n\n\n\nGrolemund, G., & Wickham, H. (2016). R for Data Science. https://r4ds.had.co.nz/\n\n\nWickham, H. (2010). A layered grammar of graphics. Journal of Computational and Graphical Statistics, 19(1), 3–28."
  }
]