---
toc-title: '![](imgs/penguin_wrestling_files.png){width=80%}<br> File-Wrangling'
---

# Import und Aufbereitung von Psychopy-Daten

## Batch-Import

```{r setup}
#| include: false

library(tidyverse)
```

Psychopy und Pavlovia schreiben Ihre Daten im long-Format raus, die dem kommenden Beispiel ähneln:

```{r}
read_csv('data/1_Experiment_Vorüberlegungen_2022_Feb_14_1902.csv') %>% 
  head()
```

Die Daten oben kommen aus einer FOV-Studie aus dem WS21 in der untersucht wurde, wie sicher sich Proband:innen bei der Entscheidung für einen t-Test oder einen anderen Test basierend auf Levene- und KS-Test-*p*-Werten sind und wie sehr sie sich in ihrer Entscheidung sicher sind..

Für jeden Probanden wird dabei eine Datei erstellt, so dass der data-folder gerne mal wie in @fig-folder aussehen kann.

![Ansicht des Daten-Ordners](imgs/folder.png){#fig-folder}

Um Auswertungen vorzubereiten müssen diese einzelnen Dateien erst mal zusammengefügt werden.

Dazu brauchen wir erst mal einen Vektor mit allen csv-files im Ordner:

```{r}
 # bei mir liegt der data-Ordner im Verzeichnis über dem in dem sich das Skript befindet
list.files(path = 'data/',
           pattern = 'csv') %>% 
  str()
```

Da bei mir ein relativer Pfad nötig ist würden die files so nicht gefunden werden, deswegen müssen wir noch das `full.names`-Argument auf `TRUE` setzen.

```{r}
list.files(path = 'data/',
           pattern = 'csv',
           full.names = T) %>% 
  str()
```

Die so erstellten Pfade können wir dann im batch öffnen und einlesen. Dazu kann der wrapper `map_dfr` um `map` und `bind_rows` aus dem `purrr`-Paket helfen:

```{r}
#| message: false
#| error: true
all_vpn <- list.files(path = 'data/',
           pattern = 'csv',
           full.names = T) %>% 
  map_dfr(~read_csv(.))
```

Der Fehler kommt daher, dass einzelne Dokumente zu kurz sind und die Spaltentypen deswegen nicht erkannt werden. Hier gibt es drei Möglichkeiten mit dem Problem umzugehen:

Bei Psychopy kann der Fehler oben nur auftreten wenn

1. etwas am Skript geändert wurde wodurch ein Datentyp in einer Datei nicht mehr stimmt. 
2. ein:e Proband:in vor dem ersten Trial eines Blocks abgebrochen hat.

Im ersten Fall habt Ihr ganz andere Probleme und solltet im Detail darüber nachdenken wie ihr das löst - oder den unschönen Weg ("The ugly") wählen.

Im zweiten Fall könnt Ihr alle zu kleinen files filtern ("The good") oder manuell ("The bad") die Spalten definieren.

:::{.panel-tabset}
### The good{#sec-good}


```{r}
#| error: true
#| message: false
files <- tibble(
  path = list.files(
    path = 'data/',
    pattern = 'csv',
    full.names = T
  ),
  size = file.size(path)
)

files %>% 
  head()

all_vpn <- files %>% 
  filter(size > mean(size)) %>% 
  pull(path) %>% 
  map_dfr(~read_csv(.))
```

### The bad{#sec-bad}

Die zweite Möglichkeit ist es, in read_csv die erwarteten Spalten-Typen anzugeben.

In meinem Fall sieht das so aus:

```{r}
#| error: true
#| message: false
all_vpn <- list.files(path = 'data/',
           pattern = 'csv',
           full.names = T) %>% 
  map_dfr(~read_csv(.,col_types = 'cnnnncnncnccnnccccnl'))
```


### The ugly{#sec-ugly}

Der uneleganteste Weg ist es erstmal alle Spalten als `character` zu importieren und dann die nötigen Spalten umzuwandeln:

```{r}
#| message: false
all_vpn <- list.files(path = 'data/',
           pattern = 'csv',
           full.names = T) %>% 
  map_dfr(~read_csv(.,col_types = cols(.default = 'c')))

all_vpn %>% 
  glimpse()
```

Aus diesem Datensatz brauchen wählen wir dann die Spalten aus, die wir brauchen und wandeln die Reaktionszeiten um (und filtern leere Zeilen).

```{r}
df <- all_vpn %>% 
  select(participant, Entscheidung.response, Ergebnisse, Sicherheit_Entscheidung.response, Sicherheit)
glimpse(df)

df <- df %>% 
  mutate(across(matches('response'), ~as.numeric(.)),
         participant = as.numeric(participant))

df <- df %>% 
  filter(!is.na(Ergebnisse))

df %>% 
  glimpse()
```


:::


Mit dem so umgewandelten Datensatz können wir dann wie gewohnt weiterarbeiten.

Zum Beispiel können wir uns die durchschnittliche Sicherheit pro Proband:in und Entscheidung ausgeben lassen:

```{r}
response_summary <- df %>% 
  group_by(participant, Ergebnisse) %>% 
  summarise(Sicherheit = mean(Sicherheit_Entscheidung.response))

response_summary %>% 
  head()
```


## Zusammenfügen

In den meisten Fällen werdet Ihr neben Psychopy-Daten noch wo anders Fragebogen dargeboten haben, die Ihr mit den Daten zusammenfügen müsst.

In unserem Beispiel existiert eine `.xlsx`-Datei, die die Limesurvey-Ergebnisse beinhaltet.

Um die zusammengefassten Ergebnisse an diese anzufügen müssen wir sie zuerst importieren:

```{r}
limesurvey_results <- openxlsx::read.xlsx('data/LimeSurvey Daten.xlsx')

limesurvey_results %>% 
  glimpse()
```

Die Zusammenfassungen sind noch im long-Format, können also nicht so einfach mit den LS-Daten im wide-Format zusammengeführt werden. Also erst einmal pivotieren:

```{r}
response_summary <- response_summary %>% 
  pivot_wider(names_from = 'Ergebnisse',
              values_from = 'Sicherheit')

response_summary %>% 
  head()
```

Die beiden Ergebnisse können wir jetzt kombinieren:

```{r}
vp_level_data <- response_summary %>% 
  left_join(limesurvey_results,
            by = c('participant' = 'VP-Nr'))

vp_level_data %>% 
  glimpse()
```

Auf den Daten können wir dann arbeiten:

```{r}
vp_level_data %>% 
  select(where(is.numeric)) %>% 
  cor()
```


## Aufgabe

```{r}
#| include: false
#| eval: false

import_and_modify <- function(path, id){
  read_table(path, col_names = F) %>% 
    set_names(nm = c('correct', 'RT')) %>% 
    mutate(participant = id,
           group = sample(1:4, 1)) %>% 
    write_csv(glue::glue('data/sim_data{id}.csv'))
  file.remove(path)
}

list.files(path = 'data/sim_data/',
           pattern = 'sim',
           full.names = T) %>%
  map2(map_chr(1:100,
               ~ paste0(
                 sample(LETTERS, 2),
                 sample(0:9, 2),
                 sample(LETTERS, 2),
                 collapse = '',
                 sep = ''
               )), 
       ~import_and_modify(.x,.y))

list.files(path = 'data/sim_data/',
           pattern = 'sim',
           full.names = T) %>% 
  sapply(\(x){file.copy(x, str_remove(x, '(?<=sim_data//)sim_data'));file.remove(x)})

read_csv('/home/brede/Nextcloud/Diss/2_exps/1_d2/src/results-survey356376.csv') %>%
  select(student, psychology, age)
  tibble(
    id = seq_along(list.files(path = 'data/sim_data/')),
    submitdate = as.POSIXct('2023-04-22 10:00:00') + rnorm(length(id), 0, 432000),
    lastpage = 6,
    startlanguage = 'de',
    seed = 1,
    startdate = submitdate - runif(length(id), 5, 15),
    datestamp = submitdate,
    pp = list.files(
      path = 'data/sim_data/',
      pattern = 'csv',
      full.names = T
    ) %>%
      str_extract('(?<=//).+(?=.csv)'),
    gender = sample(c('männlich', 'weiblich', NA), length(id), T, prob = c(.45,.45,.1)),
    student = sample(c('ja', 'nein', NA), length(id), T, prob = c(.3,.3,.4)),
    psychology = ifelse(student == 'ja', 
                        sample(c('ja', 'nein'), length(id), T, prob = c(.5,.5)),
                        NA),
    age = round(rnorm(length(id), 18, 99))
  ) %>% 
    openxlsx::write.xlsx('data/sim_data/results-survey666517.xlsx')
  
```


1. Im Repo zu diesem Skript ist eine zip-Datei mit simulierten Daten eines fiktiven Reaktionszeit-Experiments zu finden. Lade [die Zip](https://github.com/MBrede/r_thesis_tools/raw/main/data/data.zip) herunter und entpacke sie.

2. Importiere die csv-Dateien in einen Datensatz

3. Berechne Accuracy, mittlere Reaktionszeit und Standardabweichung der Reaktionszeit pro Proband:in

4. Füge die Ergebnisse mit der LimeSurvey-`xlsx` zusammen und erstelle eine Zusammenfassung der Reaktionszeiten und Accuracy pro angegebenem Geschlecht